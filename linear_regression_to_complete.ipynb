{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show how to make a linear regression with the help of the `Tensorflow` library. As an example, a set of OpenStreetMap elements gathered around Bordeaux will be used. The goal of the notebook is to predict the number of contributors for each element, starting from a set of other element characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: module imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib` will be used to plot regression results, `os` is necessary for relative path handling, then `pandas` is used to handle the input dataframe, and of course, `tensorflow` will be needed to do the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: data recovering and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The used data describes a set of OSM elements, we admit it is available on the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/rde/data/osm-history/output-extracts/bordeaux-metropole/element-metadata.csv\", index_col=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2760999 individuals in this table, described by 17 different features. One can provide a short extract of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(6).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, we will consider the number of contributors as the output to predict. We select a small set of features as predictors: the number of days between first and last modifications, the number of days since first modification, the number of days during which modifications arised, the last version, the number of change sets and the numbers of autocorrections and corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data_x and data_y, two subsets of data that will be respectively the predictors and the predicted feature\n",
    "# list of features to integrate into data_x: \"lifespan\", \"n_inscription_days\", \"n_activity_days\", \"version\", \"n_chgset\", \"n_autocorr\", \"n_corr\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a good practice, we can use the dedicated `sklearn` function to split the dataset into **train** and **test** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the accurate module from sklearn.model_selection\n",
    "\n",
    "# Create four arrays x_train, x_test, y_train and y_test with train_test_split function (test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tensorflow model design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sake of readability (code) and clarity (graph visualization), we will use `tf.name_scope` from now. The model design will be far more cleaner with this kind of context manager.\n",
    "\n",
    "First we need two tensors, *i.e.* one for inputs and one for outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the context manager (based on tf.name_scope)\n",
    "\n",
    "    # Create the placeholders X and Y (tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression is defined through weights and biases, that are set as tensorflow variables, and injected into the output variable `predictions`. The linear model is as follows:\n",
    "\n",
    "`Y[N,1] = X[N,k] * W[k,1] + b[1,1]` (`k` being the number of predictors, `W` the vector of weights, and `b` the bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new context manager containing the model definition (let say 'linear_reg')\n",
    "\n",
    "    # Create the weights associated to each predictors (initializer=tf.truncated_normal_initializer()), be careful to shape!\n",
    "    \n",
    "    # Create the bias associated to the model (initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    # Create an other tensor for the model prediction (recall the linear model definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is the sum of squares of differences between predictions and true outputs. A regularization term is added to this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new context manager containing the loss (objective function, to minimize)\n",
    "\n",
    "    # Create the loss function, by using tf.reduce_sum and tf.square (+ regularization value 0.01*tf.nn.l2_loss(w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Adam optimizer to update the model variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new context manager containing the optimizer\n",
    "\n",
    "    # Declare the minimization of the loss through the optimizer (tf.train.AdamOptimizer, alternative choice: GradientDescentOptimizer, ...)\n",
    "    # Use learning_rate as a parameter of the optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Variable initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize all the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final step: running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to open a new session, initialize the variable, and prepare the graph (and checkpoint utilities):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Old way of session opening (only for this notebook purpose!)\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the initializer tensor\n",
    "\n",
    "# Create a graph summary (tf.summary.FileWriter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is ready to be trained. We proceed to as many training steps as indicated by the previous parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = list()\n",
    "weights = list()\n",
    "biases = list()\n",
    "for epoch in range(training_epochs):\n",
    "    # Run the linear regression model with train data (by using feed_dict parameter of session.run)\n",
    "\n",
    "    # Print the current state of training according to epoch value\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        # Re-run the model without train it, for printing purpose\n",
    "\n",
    "        print(\"*** Epoch\", '%04d' % (epoch+1), \"cost={}\\nn_user = {:.3f}*X1 + {:.3f}*X2 + {:.3f}*X3 + {:.3f}*X4 + {:.3f}*X5 + {:.3f}*X6 + {:.3f}*X7 + {:.3f} ***\"\n",
    "              .format(training_cost, weight[0][0], weight[1][0], weight[2][0], weight[3][0], weight[4][0], weight[5][0], weight[6][0], bias[0]))\n",
    "        # Store the model results into dedicated lists\n",
    "        costs.append(training_cost)\n",
    "        weights.append(weight[:,0])\n",
    "        biases.append(bias[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are stored into a pandas dataframe (and may be saved onto the file system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_history = pd.DataFrame(weights,columns=[\"lifespan\", \"n_inscription_days\", \"n_activity_days\", \"version\", \"n_chgset\", \"n_autocorr\", \"n_corr\"])\n",
    "param_history[\"bias\"] = biases\n",
    "param_history[\"loss\"] = costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the results for plotting purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(12,6))\n",
    "for i in range(param_history.shape[1]):\n",
    "    ax[i % 3][int(i / 3)].plot(param_history.iloc[:,i])\n",
    "    ax[i % 3][int(i / 3)].set_title(param_history.columns[i])\n",
    "f.tight_layout()\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the model is run with test data (this dataset was not used for model training). The goal is to evaluate the correspondance between true value of `y` and the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on test data, to get its predictions\n",
    "\n",
    "print(\"Test cost = {}, i.e. +/- {:.3f} contributor(s) per OSM elements on average\"\n",
    "      .format(cost, math.sqrt(cost/len(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last plot is produced starting from the test step: it shows how good the predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_pred, 'go')\n",
    "output_min, output_max = int(min(y_pred)[0]), int(max(y_pred)[0])\n",
    "plt.plot(range(output_min, output_max+2), range(output_min, output_max+2))\n",
    "plt.xlabel(\"True values of y\")\n",
    "plt.ylabel(\"Model predictions\")\n",
    "plt.xlim(min(y_test)[0], max(y_test)[0]+2)\n",
    "plt.ylim(output_min, output_max+2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last the tensorflow session is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the session\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
